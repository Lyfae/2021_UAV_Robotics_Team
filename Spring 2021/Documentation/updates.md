**update 4/9/2021**: On the github in my branch, I updated the software folder with the webcam code and some basic yolo setup. the webcam code can be run without the CUDA setup process w/ tensorflow and I got it to work on Michael's computer. In order to run the train.py file in the yolo folder, you need to set up CUDA to have tensorflow work with your computer's GPU. The file is basically a data scraping test script that is used for testing the speed of GPU, along with validating the tensorflow download. [C.L.]

My next step would be to set up live detection using a combination of the code in both folders, as well as running the program with the included default weights (person, cell phone, common objects like these) and begin to train the algorithm to recognize basic electrical components I currently own (PCBs, DIPs, etc) [C.L.]

**update 4/10/2021**: I figured out that my pip install opencv version was not working with CUDA support using the cv2.cuda.getCudaEnabledDeviceCount() python command. I spent about 4 hours today working with CMake and the raw source code from the open soruce opencv github repository to get a fresh version of opencv-gpu support on my computer. I'm keeping in mind that every software step I make will have to be mirrored on Michael's computer and then the jetson(?) afterwards. [C.L.]

**update 4/11/2021**: Meeting with Paul tomorrow morning to figure out more progress stuff. Current target goal is to get opencv to collab with tensorflow, which uses GPU, to detect COCO (common objects in context) images in real time. I'm about 60% of the way there, I just need a bit more info from Paul and a lotta bug testing. I'll be continuously updating my branch in GitHub with code, and pushing it to Michael's computer whenever I get the chance. [C.L.]